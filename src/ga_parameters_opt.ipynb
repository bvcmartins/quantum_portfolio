{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "seed = 12\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(weights, data):\n",
    "    data_returns = np.log(data) - np.log(data.shift(1)) # current day - previous day\n",
    "    data_returns = data_returns.dropna()\n",
    "    portfolio_returns = np.dot(data_returns, weights)\n",
    "    portfolio_mean = np.mean(portfolio_returns)\n",
    "    portfolio_std = np.sum(np.sum(weights * np.std(portfolio_returns) * data.corr().values * np.std(portfolio_returns).T * weights.T, axis=1), axis=0)\n",
    "    sharpe_ratio = (portfolio_mean / portfolio_std) \n",
    "    return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa825c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(data, population_size=500, num_generations=1000, mutation_rate=0.05, elitism=0.1):\n",
    "    population = np.random.rand(population_size, len(data.columns))\n",
    "    population = population / np.sum(population, axis=1)[:, np.newaxis]\n",
    "    mean_fitness = []\n",
    "    max_fitness = []\n",
    "    fitness = np.array([fitness_function(individual, data) for individual in population])\n",
    "    for generation in range(num_generations):\n",
    "        sorted_idx = np.argsort(fitness)[::-1]\n",
    "        population = population[sorted_idx]\n",
    "        fitness = fitness[sorted_idx]\n",
    "        num_elites = int(elitism * population_size)\n",
    "        offspring = population[:num_elites]\n",
    "        parent1_idx = np.random.randint(num_elites, population_size, size=population_size-num_elites)\n",
    "        parent2_idx = np.random.randint(num_elites, population_size, size=population_size-num_elites)\n",
    "        parent1 = population[parent1_idx]\n",
    "        parent2 = population[parent2_idx]\n",
    "        crossover_prob = np.random.rand(population_size-num_elites, len(data.columns))\n",
    "        crossover_mask = crossover_prob <= 0.5\n",
    "        offspring_crossover = np.where(crossover_mask, parent1, parent2)\n",
    "        mutation_prob = np.random.rand(population_size-num_elites, len(data.columns))\n",
    "        mutation_mask = mutation_prob <= 0.5\n",
    "        mutation_values = np.random.rand(population_size-num_elites, len(data.columns))\n",
    "        mutation_direction = np.random.choice([-1, 1], size=(population_size - num_elites, len(data.columns)))\n",
    "        offspring_mutation = np.where(mutation_mask, offspring_crossover + mutation_direction * mutation_values, offspring_crossover)\n",
    "        population = np.vstack((population[:num_elites], offspring_mutation))\n",
    "        fitness = np.array([fitness_function(individual, data) for individual in population])\n",
    "    selected = []\n",
    "    # consider only solutions where all weights are greater than zero\n",
    "    for f in fitness:\n",
    "        if np.all(f > 0):\n",
    "            selected.append(f)\n",
    "    best_idx = np.argmax(selected)\n",
    "    best_individual = population[best_idx]\n",
    "    # 'Best Sharpe Ratio: ', np.max(fitness)\n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df, benchmark, days_to_avg=30, days_to_opt=30):\n",
    "\n",
    "    df2 = df.reset_index()\n",
    "    benchmark2 = benchmark.reset_index()\n",
    "    elements = df2.sample(n=100).index # definint a maximum of 100 different sampled initial dates\n",
    "    for idx in elements:\n",
    "        df_sample = df2.iloc[idx-days_to_avg:idx+days_to_opt, :]\n",
    "        df_sample = df_sample.set_index('ds')\n",
    "        df_sample_b = benchmark2.iloc[idx-days_to_avg:idx+days_to_opt, :]\n",
    "        df_sample_b = df_sample_b.set_index('ds')\n",
    "        yield df_sample, df_sample_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb256e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(optimization_function, data, benchmark, initial_capital, avg_period, opt_period):\n",
    "    portfolio_value = initial_capital\n",
    "    portfolio_returns = []\n",
    "    benchmark_returns = []\n",
    "    weights_history = pd.DataFrame(index=data.index, columns=data.columns)\n",
    "    portfolio_value_history = pd.Series(index=data.index, name='Portfolio Value', dtype='float')\n",
    "    portfolio_value_history.iloc[0] = portfolio_value\n",
    "    #print(len())\n",
    "    j = 0\n",
    "    for i in range(avg_period+1, avg_period + opt_period+1):\n",
    "        df = data.iloc[j:i, :]\n",
    "        weights = optimization_function(df)\n",
    "        weights[weights < 0] = 0\n",
    "        weights /= weights.sum()\n",
    "        weights_history.loc[df.index[-1]] = weights\n",
    "        portfolio_change = df.iloc[-2:, :].pct_change() * weights\n",
    "        portfolio_return = portfolio_change.sum(axis=1).iloc[-1]\n",
    "        portfolio_returns.append(portfolio_return)\n",
    "        # #print(f'portfolio_returns: {portfolio_returns}')\n",
    "        benchmark_return = benchmark.iloc[j:i, :].pct_change().iloc[-1].values.tolist()[0]\n",
    "        benchmark_returns.append(benchmark_return)\n",
    "        portfolio_cumulative_returns = np.cumprod([k + 1 for k in portfolio_returns])\n",
    "\n",
    "        benchmark_cumulative_returns = np.cumprod([k + 1 for k in  benchmark_returns])\n",
    "        portfolio_mean_return = np.mean(portfolio_returns)\n",
    "        benchmark_mean_return = np.mean(benchmark_returns)\n",
    "        portfolio_volatility = np.std(portfolio_returns) #* np.sqrt(12)\n",
    "        benchmark_volatility = np.std(benchmark_returns) #* np.sqrt(12)\n",
    "        try:\n",
    "            sharpe_ratio = (portfolio_mean_return) / portfolio_volatility\n",
    "        except Exception as e:\n",
    "            sharpe_ratio = 0\n",
    "        try:\n",
    "            benchmark_sharpe_ratio = (benchmark_mean_return) / benchmark_volatility\n",
    "        except Exception as e:\n",
    "            benchmark_sharpe_ratio = 0\n",
    "\n",
    "         # Portfolio & Benchmark value\n",
    "        benchmark_value = initial_capital * benchmark_cumulative_returns[-1]\n",
    "        portfolio_value = initial_capital * portfolio_cumulative_returns[-1]\n",
    "\n",
    "        j += 1\n",
    "    return weights_history, portfolio_value_history, portfolio_cumulative_returns, benchmark_cumulative_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dict(data, file_path):\n",
    "    \"\"\"Pickles a dictionary and saves it to a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:  # Open the file in binary write mode ('wb')\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"Dictionary pickled and saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while pickling: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_path = '../data/benchmark_gspc.pkl'\n",
    "source_path = '../data/stocks_adjclose.pkl'\n",
    "benchmark = pd.read_pickle(benchmark_path)\n",
    "source = pd.read_pickle(source_path)\n",
    "\n",
    "# correlation analysis\n",
    "df_corr = source.corr()\n",
    "corr_sum = df_corr.map(lambda x: abs(x)).sum()\n",
    "corr_rank = corr_sum.sort_values().rank(method='min').astype(int)\n",
    "corr_rank\n",
    "\n",
    "return_rank = source.diff().sum(axis=0).sort_values().rank(method='min', ascending=False).astype(int)\n",
    "\n",
    "# Select test set \n",
    "select_20 = (return_rank + corr_rank).sort_values().reset_index()['Ticker'].values[:21]\n",
    "data = source[select_20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7768eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size=[10, 100, 1000]\n",
    "num_generations=[10, 100, 1000]\n",
    "mutation_rate=[0.01, 0.1, 0.2]\n",
    "elitism=[0.01, 0.5, 0.1]\n",
    "n_periods = 10\n",
    "days_to_avg = 30\n",
    "days_to_opt = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3911a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "combs = [i for i in itertools.product(population_size, num_generations, mutation_rate, elitism)]\n",
    "n = 0\n",
    "datagen = generate_data(data, benchmark)\n",
    "df, df_b = next(datagen)\n",
    "parameters = []\n",
    "max_returns = 0\n",
    "while n < len(combs):\n",
    "    p, n, m, e = random.choice(combs)\n",
    "    opt_fun = partial(genetic_algorithm, population_size=p, num_generations=n, mutation_rate=m, elitism=e)\n",
    "    weights_history, portfolio_value_history, portfolio_cumulative_returns, benchmark_cumulative_returns = backtest(opt_fun, df, df_b, initial_capital=1000, avg_period=30, opt_period=30)\n",
    "    result = {\n",
    "        \"start_date\": df.index[0],\n",
    "        \"end_date\": df.index[-1],\n",
    "        \"population_size\": population_size,\n",
    "        \"num_generations\": num_generations,\n",
    "        \"days_to_avg\": days_to_avg,\n",
    "        \"days_to_opt\": days_to_opt,\n",
    "        \"weights_history\": weights_history,\n",
    "        \"portfolio_value_history\": portfolio_value_history,\n",
    "        \"portfolio_cumulative_returns\": portfolio_cumulative_returns,\n",
    "        \"sum_cumulative_returns\": sum(portfolio_cumulative_returns)\n",
    "        }\n",
    "    \n",
    "    parameters.append(result)\n",
    "    if sum(portfolio_cumulative_returns) > max_returns:\n",
    "        max_returns = sum(portfolio_cumulative_returns)\n",
    "        print(f'pop size: {p}, n gen: {n}, mut: {m}, elit: {e}, portfolio_cumulative_returns: {portfolio_cumulative_returns}')\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25d26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liquidity_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
